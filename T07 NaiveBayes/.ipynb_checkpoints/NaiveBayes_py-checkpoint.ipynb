{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c3bcf96-f2d9-4d0e-a478-aa244b1ceb98",
   "metadata": {},
   "source": [
    "# T07: Naive Bayes and Cross-Validation\n",
    "\n",
    "TA: HUANG Xinrui, HKUST\n",
    "\n",
    "Date: October 24, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074539ae-4f02-4ab5-bb75-6ec0a3433cd3",
   "metadata": {},
   "source": [
    "## Naive Bayes Classification\n",
    "\n",
    "Recall that the classifcation implied by Bayes Theorem\n",
    "\n",
    "$$\n",
    "\\Pr(y=k|X=x)=\\frac{\\pi_kf_k(x)}{\\sum_{l=1}^K\\pi_lf_l(x)},\n",
    "$$\n",
    "\n",
    "where $X\\in\\mathbb{R}^p, y\\in\\mathbb{R}^n$.\n",
    "\n",
    "- For __LDA__, we have \n",
    "$$X|y=k\\sim\\mathcal{N}(\\mu_k,\\Sigma),\\ \\text{then} \\ f_k(x)=\\frac{1}{(2\\pi)^{p/2}|\\Sigma|^{1/2}}\\exp(-\\frac{1}{2}(x-\\mu_k)^T\\Sigma^{-1}(x-\\mu_k)).$$\n",
    "\n",
    "    - Assign an observation $X=x$ to the class $k$ for which $\\Pr(y=k|X=x)>\\Pr(y=k'|X=x)$, where $k'\\neq k$.\n",
    "\n",
    "    - This is equivalent to assigning an observation $X=x$ to the class $k$ for which \n",
    "    $$\\delta_k(x)=x^T\\Sigma^{-1}\\mu_k-\\frac{1}{2}\\mu_k^T\\Sigma^{-1}\\mu_k+\\log\\pi_k$$\n",
    "    is largest.\n",
    "\n",
    "- For __QDA__, we have\n",
    "$$X|y=k\\sim\\mathcal{N}(\\mu_k,\\color{red}{\\Sigma_k}),\\ \\text{then} \\ f_k(x)=\\frac{1}{(2\\pi)^{p/2}|\\color{red}{\\Sigma_k}|^{1/2}}\\exp(-\\frac{1}{2}(x-\\mu_k)^T\\color{red}{\\Sigma_k}^{-1}(x-\\mu_k)).$$\n",
    "It assigns an observation $X=x$ to the class for which \n",
    "$$\\delta_k(x)=\\color{red}{-\\frac{1}{2}x^T\\Sigma_k^{-1}x}+x^T\\color{red}{\\Sigma_k}^{-1}\\mu_k-\\frac{1}{2}\\mu_k^T\\color{red}{\\Sigma_k}^{-1}\\mu_k-\\color{red}{\\frac{1}{2}\\log|\\Sigma_k|}+\\log\\pi_k$$\n",
    "is largest.\n",
    "\n",
    "We can consider an even simpler model, the __Naive Bayes__,  which assumes __conditional independence__ between $X_j$'s:\n",
    "\n",
    "$$X_j|y=k\\sim\\mathcal{N}(\\mu_{jk},\\sigma_{jk}^2),$$then$$f_k(x)=\\prod_{j=1}^p\\mathcal{N}(\\mu_{jk},\\sigma_{jk}^2)=\\frac{1}{(2\\pi)^{p/2}\\color{red}{\\prod_{j=1}^p\\sigma_{jk}}}\\exp(\\sum_{j=1}^p-\\frac{(x_j-\\mu_{jk})^2}{2\\color{red}{\\sigma_{jk}^2}}).$$\n",
    "- Equivalent to setting all the off-diagonal elements of $\\Sigma$ in LDA to zero\n",
    "- Assign an observation $X=x$ to the class $k$ for which $\\Pr(y=k|X=x)>\\Pr(y=k'|X=x)$, where $k'\\neq k$\n",
    "- This is equivalent to assigning an observation $X=x$ to the class $k$ for which \n",
    "$$\\delta_k(x)=-\\frac{1}{2}\\sum_{j}\\frac{x_j^Tx_j}{\\sigma_{jk}^2} + \\sum_{j}x_j\\frac{\\mu_{jk}}{\\sigma_{jk}^2}-\\frac{1}{2}\\frac{\\mu_{jk}^2}{\\sigma_{jk}^2}+\\log\\pi_k$$\n",
    "is largest.\n",
    "\n",
    "We are going to compare the performance of Naive Bayes and QDA using simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b4d495-1ba8-44a4-a54a-a7f64378a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0879a0-2fdf-4314-abd5-b97e0b7404e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20231024)\n",
    "\n",
    "ntrain = 200\n",
    "ntest = 500\n",
    "n = ntrain + ntest\n",
    "idx_train = np.arange(ntrain)\n",
    "idx_test = np.arange(ntrain, n)\n",
    "\n",
    "p = 15 # Number of predictors\n",
    "beta = np.random.normal(size=p) # Coefficients\n",
    "\n",
    "trial = 30 # Number of trials\n",
    "\n",
    "Sig = 0.9**(np.abs(np.subtract.outer(np.arange(1,p+1), np.arange(1,p+1)))) # Covariance matrix, outer product function np.fill_diagonal(Sig, 1) Sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93e72244-2f02-4bf0-9ea1-3e8b3b132281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15, 15),\n",
       " array([[1.        , 0.9       , 0.81      , 0.729     , 0.6561    ,\n",
       "         0.59049   , 0.531441  , 0.4782969 , 0.43046721, 0.38742049,\n",
       "         0.34867844, 0.3138106 , 0.28242954, 0.25418658, 0.22876792],\n",
       "        [0.9       , 1.        , 0.9       , 0.81      , 0.729     ,\n",
       "         0.6561    , 0.59049   , 0.531441  , 0.4782969 , 0.43046721,\n",
       "         0.38742049, 0.34867844, 0.3138106 , 0.28242954, 0.25418658],\n",
       "        [0.81      , 0.9       , 1.        , 0.9       , 0.81      ,\n",
       "         0.729     , 0.6561    , 0.59049   , 0.531441  , 0.4782969 ,\n",
       "         0.43046721, 0.38742049, 0.34867844, 0.3138106 , 0.28242954],\n",
       "        [0.729     , 0.81      , 0.9       , 1.        , 0.9       ,\n",
       "         0.81      , 0.729     , 0.6561    , 0.59049   , 0.531441  ,\n",
       "         0.4782969 , 0.43046721, 0.38742049, 0.34867844, 0.3138106 ],\n",
       "        [0.6561    , 0.729     , 0.81      , 0.9       , 1.        ,\n",
       "         0.9       , 0.81      , 0.729     , 0.6561    , 0.59049   ,\n",
       "         0.531441  , 0.4782969 , 0.43046721, 0.38742049, 0.34867844],\n",
       "        [0.59049   , 0.6561    , 0.729     , 0.81      , 0.9       ,\n",
       "         1.        , 0.9       , 0.81      , 0.729     , 0.6561    ,\n",
       "         0.59049   , 0.531441  , 0.4782969 , 0.43046721, 0.38742049],\n",
       "        [0.531441  , 0.59049   , 0.6561    , 0.729     , 0.81      ,\n",
       "         0.9       , 1.        , 0.9       , 0.81      , 0.729     ,\n",
       "         0.6561    , 0.59049   , 0.531441  , 0.4782969 , 0.43046721],\n",
       "        [0.4782969 , 0.531441  , 0.59049   , 0.6561    , 0.729     ,\n",
       "         0.81      , 0.9       , 1.        , 0.9       , 0.81      ,\n",
       "         0.729     , 0.6561    , 0.59049   , 0.531441  , 0.4782969 ],\n",
       "        [0.43046721, 0.4782969 , 0.531441  , 0.59049   , 0.6561    ,\n",
       "         0.729     , 0.81      , 0.9       , 1.        , 0.9       ,\n",
       "         0.81      , 0.729     , 0.6561    , 0.59049   , 0.531441  ],\n",
       "        [0.38742049, 0.43046721, 0.4782969 , 0.531441  , 0.59049   ,\n",
       "         0.6561    , 0.729     , 0.81      , 0.9       , 1.        ,\n",
       "         0.9       , 0.81      , 0.729     , 0.6561    , 0.59049   ],\n",
       "        [0.34867844, 0.38742049, 0.43046721, 0.4782969 , 0.531441  ,\n",
       "         0.59049   , 0.6561    , 0.729     , 0.81      , 0.9       ,\n",
       "         1.        , 0.9       , 0.81      , 0.729     , 0.6561    ],\n",
       "        [0.3138106 , 0.34867844, 0.38742049, 0.43046721, 0.4782969 ,\n",
       "         0.531441  , 0.59049   , 0.6561    , 0.729     , 0.81      ,\n",
       "         0.9       , 1.        , 0.9       , 0.81      , 0.729     ],\n",
       "        [0.28242954, 0.3138106 , 0.34867844, 0.38742049, 0.43046721,\n",
       "         0.4782969 , 0.531441  , 0.59049   , 0.6561    , 0.729     ,\n",
       "         0.81      , 0.9       , 1.        , 0.9       , 0.81      ],\n",
       "        [0.25418658, 0.28242954, 0.3138106 , 0.34867844, 0.38742049,\n",
       "         0.43046721, 0.4782969 , 0.531441  , 0.59049   , 0.6561    ,\n",
       "         0.729     , 0.81      , 0.9       , 1.        , 0.9       ],\n",
       "        [0.22876792, 0.25418658, 0.28242954, 0.3138106 , 0.34867844,\n",
       "         0.38742049, 0.43046721, 0.4782969 , 0.531441  , 0.59049   ,\n",
       "         0.6561    , 0.729     , 0.81      , 0.9       , 1.        ]]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sig.shape, Sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b46053fe-8df0-4034-8b0a-953c04fc41cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial</th>\n",
       "      <th>QDA</th>\n",
       "      <th>Naive Bayes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.427104</td>\n",
       "      <td>0.587026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.508423</td>\n",
       "      <td>0.861489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.494449</td>\n",
       "      <td>1.185613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.436921</td>\n",
       "      <td>0.810996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.532141</td>\n",
       "      <td>0.812195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trial       QDA  Naive Bayes\n",
       "0    1.0  0.427104     0.587026\n",
       "1    2.0  0.508423     0.861489\n",
       "2    3.0  0.494449     1.185613\n",
       "3    4.0  0.436921     0.810996\n",
       "4    5.0  0.532141     0.812195"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = np.zeros((trial, 2)) # Error matrix\n",
    "\n",
    "for i in range(trial):\n",
    "    X = multivariate_normal(mean=np.zeros(p), cov=Sig).rvs(n)\n",
    "    t = np.dot(X, beta)\n",
    "    prob = 1 / (1 + np.exp(-t))\n",
    "    y = np.random.binomial(1, prob, n)\n",
    "    dat = pd.DataFrame(np.column_stack((X, y)), columns=[f\"X{j}\" for j in range(1,p+1)]+[\"y\"])\n",
    "    \n",
    "    fit_qda = QuadraticDiscriminantAnalysis().fit(dat.iloc[idx_train,:-1], dat.iloc[idx_train,-1])\n",
    "    pred_qda = fit_qda.predict_proba(dat.iloc[idx_test,:-1])\n",
    "    err_qda = -np.sum(dat.iloc[idx_test,-1] * np.log(pred_qda[:,1]) + (1 - dat.iloc[idx_test,-1]) * np.log(pred_qda[:,0])) / ntest\n",
    "    err[i, 0] = err_qda\n",
    "\n",
    "    fit_nb = GaussianNB().fit(dat.iloc[idx_train,:-1], dat.iloc[idx_train,-1])\n",
    "    pred_nb = fit_nb.predict_proba(dat.iloc[idx_test,:-1])\n",
    "    err_nb = -np.sum(dat.iloc[idx_test,-1] * np.log(pred_nb[:,1]) + (1 - dat.iloc[idx_test,-1]) * np.log(pred_nb[:,0])) / ntest\n",
    "    err[i, 1] = err_nb\n",
    "\n",
    "err = pd.DataFrame(np.column_stack((np.arange(1,trial+1), err)), columns=[\"Trial\", \"QDA\", \"Naive Bayes\"])\n",
    "err.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e2c2ae3-06d2-4ec2-9f33-029dc9d43da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trial</th>\n",
       "      <th>Method</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>QDA</td>\n",
       "      <td>0.427104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>QDA</td>\n",
       "      <td>0.508423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>QDA</td>\n",
       "      <td>0.494449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>QDA</td>\n",
       "      <td>0.436921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>QDA</td>\n",
       "      <td>0.532141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Trial Method     Error\n",
       "0    1.0    QDA  0.427104\n",
       "1    2.0    QDA  0.508423\n",
       "2    3.0    QDA  0.494449\n",
       "3    4.0    QDA  0.436921\n",
       "4    5.0    QDA  0.532141"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = pd.melt( frame=err, id_vars=\"Trial\", value_vars=[\"QDA\", \"Naive Bayes\"], var_name=\"Method\", value_name=\"Error\" )\n",
    "err.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b7984a-520e-48de-a9ce-988ee4258b00",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/gs/dmw0lg590hsgknf6yjwxplb40000gn/T/ipykernel_35600/2419217470.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_scale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"whitegrid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.boxplot(x=\"Method\", y=\"Error\", data=err)\n",
    "ax.set(xlabel='Method', ylabel='Error', title='Comparison of QDA and Naive Bayes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18027dc-d06a-408e-9d7d-df5fd25eee49",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20231024)\n",
    "\n",
    "ntrain = 200\n",
    "ntest = 500\n",
    "n = ntrain + ntest\n",
    "idx_train = np.arange(ntrain)\n",
    "idx_test = np.arange(ntrain, n)\n",
    "\n",
    "p = 50 # Number of predictors\n",
    "beta = np.random.normal(size=p) # Coefficients\n",
    "\n",
    "trial = 30 # Number of trials\n",
    "\n",
    "Sig = 0.9**(np.abs(np.subtract.outer(np.arange(1,p+1), np.arange(1,p+1)))) # Covariance matrix, outer product function np.fill_diagonal(Sig, 1)\n",
    "\n",
    "err = np.zeros((trial, 2)) # Error matrix\n",
    "\n",
    "for i in range(trial):\n",
    "    X = multivariate_normal(mean=np.zeros(p), cov=Sig).rvs(n)\n",
    "    t = np.dot(X, beta)\n",
    "    prob = 1 / (1 + np.exp(-t))\n",
    "    y = np.random.binomial(1, prob, n)\n",
    "    dat = pd.DataFrame(np.column_stack((X, y)), columns=[f\"X{j}\" for j in range(1,p+1)]+[\"y\"])\n",
    "\n",
    "    fit_qda = QuadraticDiscriminantAnalysis().fit(dat.iloc[idx_train,:-1], dat.iloc[idx_train,-1])\n",
    "    pred_qda = fit_qda.predict_proba(dat.iloc[idx_test,:-1])\n",
    "    err_qda = -np.sum(dat.iloc[idx_test,-1] * np.log(pred_qda[:,1]) + (1 - dat.iloc[idx_test,-1]) * np.log(pred_qda[:,0])) / ntest\n",
    "    err[i, 0] = err_qda\n",
    "\n",
    "    fit_nb = GaussianNB().fit(dat.iloc[idx_train,:-1], dat.iloc[idx_train,-1])\n",
    "    pred_nb = fit_nb.predict_proba(dat.iloc[idx_test,:-1])\n",
    "    err_nb = -np.sum(dat.iloc[idx_test,-1] * np.log(pred_nb[:,1]) + (1 - dat.iloc[idx_test,-1]) * np.log(pred_nb[:,0])) / ntest\n",
    "    err[i, 1] = err_nb\n",
    "\n",
    "err = pd.DataFrame(np.column_stack((np.arange(1,trial+1), err)), columns=[\"Trial\", \"QDA\", \"Naive Bayes\"])\n",
    "err = pd.melt( frame=err, id_vars=\"Trial\", value_vars=[\"QDA\", \"Naive Bayes\"], var_name=\"Method\", value_name=\"Error\" )\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.boxplot(x=\"Method\", y=\"Error\", data=err)\n",
    "ax.set(xlabel='Method', ylabel='Error', title='Comparison of QDA and Naive Bayes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b2ad46-726b-4521-a21b-55af0f49e2a4",
   "metadata": {},
   "source": [
    "Short summary of __bias-variance tradeoff__\n",
    "\n",
    "- QDA performs well when the sample size is large.\n",
    "- Naive Bayes can outperforms QDA with small sample size even with the violence of assumption.\n",
    "\n",
    "Try to think about it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73f9aa9-ff58-4133-bf43-379075e50aca",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "In application, dividing the data into training and test sets may be a waste of information.\n",
    "To fully use the whole dataset, we can apply the cross-validation strategy.\n",
    "\n",
    "- Randomly partition the sample into $k$ equal-sized subsamples.\n",
    "- Of the $k$ subsamples, a single subsample is retained as the validation data for testing the model, and the remaining $k âˆ’ 1 $subsamples are used as training data.\n",
    "- The cross-validation process is then repeated $k$ times, with each of the $k$ subsamples used exactly once as the validation data. \n",
    "- The $k$ results can then be averaged to produce a single estimation.\n",
    "- All observations are used for both training and validation, and each observation is used for validation exactly once.\n",
    "- 5 or 10 folds are usually used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074f131d-3128-4455-aed5-6b83ed08545b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "np.random.seed(20231024)\n",
    "\n",
    "n = 200 # Sample size\n",
    "nfolds = 10 # Number of folds for cross-validation\n",
    "\n",
    "p = 15 # Number of predictors\n",
    "beta = np.random.normal(size=p) # Coefficients\n",
    "\n",
    "Sig = 0.9**(np.abs(np.subtract.outer(np.arange(1,p+1), np.arange(1,p+1)))) # Covariance matrix, outer product function np.fill_diagonal(Sig, 1)\n",
    "\n",
    "X = multivariate_normal(mean=np.zeros(p), cov=Sig).rvs(n)\n",
    "t = np.dot(X, beta)\n",
    "prob = 1 / (1 + np.exp(-t))\n",
    "y = np.random.binomial(1, prob, n)\n",
    "dat = pd.DataFrame(np.column_stack((X, y)), columns=[f\"X{j}\" for j in range(1,p+1)]+[\"y\"])\n",
    "\n",
    "dat_idx = np.random.choice(np.arange(n), n, replace=False)\n",
    "cv_err = np.zeros((nfolds, 2))\n",
    "kf = KFold(n_splits=nfolds)\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(dat)):\n",
    "    fit_qda = QuadraticDiscriminantAnalysis().fit(dat.iloc[train_idx,:-1], dat.iloc[train_idx,-1])\n",
    "    pred_qda = fit_qda.predict_proba(dat.iloc[test_idx,:-1])\n",
    "    err_qda = -np.sum(dat.iloc[test_idx,-1] * np.log(pred_qda[:,1]) + (1 - dat.iloc[test_idx,-1]) * np.log(pred_qda[:,0])) / (n / nfolds)\n",
    "    cv_err[i, 0] = err_qda\n",
    "    \n",
    "    fit_nb = GaussianNB().fit(dat.iloc[train_idx,:-1], dat.iloc[train_idx,-1])\n",
    "    pred_nb = fit_nb.predict_proba(dat.iloc[test_idx,:-1])\n",
    "    err_nb = -np.sum(dat.iloc[test_idx,-1] * np.log(pred_nb[:,1]) + (1 - dat.iloc[test_idx,-1]) * np.log(pred_nb[:,0])) / (n / nfolds)\n",
    "    cv_err[i, 1] = err_nb\n",
    "\n",
    "cv_err = pd.DataFrame(np.column_stack((np.arange(1,nfolds+1), cv_err)), columns=[\"Fold\", \"QDA\", \"Naive Bayes\"])\n",
    "cv_err = pd.melt( frame=cv_err, id_vars=\"Fold\", value_vars=[\"QDA\", \"Naive Bayes\"], var_name=\"Method\", value_name=\"Error\" )\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.boxplot(x=\"Method\", y=\"Error\", data=cv_err)\n",
    "ax.set(xlabel='Method', ylabel='Error', title='Comparison of QDA and Naive Bayes with Cross-Validation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb30f20a-1d5c-43a0-86e4-565b30f432d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20231024)\n",
    "\n",
    "n = 200 # Sample size\n",
    "nfolds = 10 # Number of folds for cross-validation\n",
    "\n",
    "p = 50 # Number of predictors\n",
    "beta = np.random.normal(size=p) # Coefficients\n",
    "\n",
    "Sig = 0.9**(np.abs(np.subtract.outer(np.arange(1,p+1), np.arange(1,p+1)))) # Covariance matrix, outer product function np.fill_diagonal(Sig, 1)\n",
    "\n",
    "X = multivariate_normal(mean=np.zeros(p), cov=Sig).rvs(n)\n",
    "t = np.dot(X, beta)\n",
    "prob = 1 / (1 + np.exp(-t))\n",
    "y = np.random.binomial(1, prob, n)\n",
    "dat = pd.DataFrame(np.column_stack((X, y)), columns=[f\"X{j}\" for j in range(1,p+1)]+[\"y\"])\n",
    "\n",
    "dat_idx = np.random.choice(np.arange(n), n, replace=False)\n",
    "cv_err = np.zeros((nfolds, 2))\n",
    "kf = KFold(n_splits=nfolds)\n",
    "\n",
    "for i, (train_idx, test_idx) in enumerate(kf.split(dat)):\n",
    "    fit_qda = QuadraticDiscriminantAnalysis().fit(dat.iloc[train_idx,:-1], dat.iloc[train_idx,-1])\n",
    "    pred_qda = fit_qda.predict_proba(dat.iloc[test_idx,:-1])\n",
    "    err_qda = -np.sum(dat.iloc[test_idx,-1] * np.log(pred_qda[:,1]) + (1 - dat.iloc[test_idx,-1]) * np.log(pred_qda[:,0])) / (n / nfolds)\n",
    "    cv_err[i, 0] = err_qda\n",
    "    \n",
    "    fit_nb = GaussianNB().fit(dat.iloc[train_idx,:-1], dat.iloc[train_idx,-1])\n",
    "    pred_nb = fit_nb.predict_proba(dat.iloc[test_idx,:-1])\n",
    "    err_nb = -np.sum(dat.iloc[test_idx,-1] * np.log(pred_nb[:,1]) + (1 - dat.iloc[test_idx,-1]) * np.log(pred_nb[:,0])) / (n / nfolds)\n",
    "    cv_err[i, 1] = err_nb\n",
    "\n",
    "cv_err = pd.DataFrame(np.column_stack((np.arange(1,nfolds+1), cv_err)), columns=[\"Fold\", \"QDA\", \"Naive Bayes\"])\n",
    "cv_err = pd.melt( frame=cv_err, id_vars=\"Fold\", value_vars=[\"QDA\", \"Naive Bayes\"], var_name=\"Method\", value_name=\"Error\" )\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "ax = sns.boxplot(x=\"Method\", y=\"Error\", data=cv_err)\n",
    "ax.set(xlabel='Method', ylabel='Error', title='Comparison of QDA and Naive Bayes with Cross-Validation')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
